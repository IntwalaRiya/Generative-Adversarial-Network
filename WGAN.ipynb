{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO6Cwm14JX3AwbcvxY+DjJS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IQ9D8BrLRIA2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592634199652,"user_tz":-330,"elapsed":1282,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}},"outputId":"c60b66c0-ac28-4cd8-b504-8706dbf12288"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AqJTcd80RPcC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592634225461,"user_tz":-330,"elapsed":7888,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}},"outputId":"342e0fc1-b5fb-4134-855d-2043e7f86ebd"},"source":["import tensorflow\n","print(tensorflow.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gEUD3PSqc7A6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592644849553,"user_tz":-330,"elapsed":20476,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}},"outputId":"4a794e0b-56af-4cad-f221-78b7f47fd2b0"},"source":["from __future__ import print_function, division\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import RMSprop\n","\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","import time\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","img_rows = 36\n","img_cols = 36\n","channels = 1\n","img_shape = (img_rows, img_cols, channels)\n","latent_dim = 100\n","\n","n_critic = 10\n","clip_value = 0.01\n","optimizer = RMSprop(lr=0.00001)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"esTWLxDbc-q8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592643613389,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}}},"source":["def build_generator():\n","  model = Sequential()\n","\n","  # model.add(Dense(128, input_dim=latent_dim))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(BatchNormalization(momentum=0.8))\n","\n","  # model.add(Dense(256))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(BatchNormalization(momentum=0.8))\n","\n","  # model.add(Dense(512))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(BatchNormalization(momentum=0.8))\n","\n","  # model.add(Dense(1024))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(BatchNormalization(momentum=0.8))\n","\n","  # model.add(Dense(np.prod(img_shape), activation='tanh'))\n","  # model.add(Reshape(img_shape))\n","\n","  model.add(Dense(256 * 9 * 9, activation=\"relu\", input_dim=latent_dim))\n","  model.add(Reshape((9, 9, 256)))\n","  model.add(UpSampling2D())\n","  \n","  model.add(Conv2D(512, kernel_size=4, padding=\"same\"))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(Activation(\"relu\"))\n","  model.add(UpSampling2D())\n","  \n","  model.add(Conv2D(512, kernel_size=4, padding=\"same\"))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(Activation(\"relu\"))\n","  \n","  model.add(Conv2D(1024, kernel_size=4, padding=\"same\"))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(Activation(\"relu\"))\n","  \n","  model.add(Conv2D(channels, kernel_size=4, padding=\"same\"))\n","  model.add(Activation(\"tanh\"))\n","\n","  model.summary()\n","  noise = Input(shape=(latent_dim,))\n","  img = model(noise)\n","\n","  return model"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"o44pJ2YFdHEu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636178824,"user_tz":-330,"elapsed":2534,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}}},"source":["def build_critic():\n","  model = Sequential()\n","  \n","  # model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding='same', input_shape=img_shape))\n","        \n","  # model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding='same'))\n","  # model.add(Dropout(0.25))\n","\n","  # model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=img_shape))\n","        \n","  # model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n","  # model.add(Dropout(0.25))\n","  # model.add(Flatten())\n","\n","  # model.add(Dense(256, activation='relu'))\n","  # model.add(Dropout(0.5))\n","  \n","  # model.add(Dense(1, activation='sigmoid'))\n","\n","  # ------------------------------------------------------------------------------------------------------------# \n","\n","  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.25))\n","  \n","  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n","  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n","  model.add(BatchNormalization(momentum=0.8))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Dropout(0.25))\n","  model.add(Flatten())\n","\n","  model.add(Dense(1))\n","\n","  # ------------------------------------------------------------------------------------------------------------# \n","  \n","  # model.add(Flatten(input_shape=img_shape))\n","  # model.add(Dense(512))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(Dense(256))\n","  # model.add(LeakyReLU(alpha=0.2))\n","  # model.add(Dense(1, activation='sigmoid'))\n","\n","  model.summary()\n","  img = Input(shape=img_shape)\n","  validity = model(img)\n","  \n","  return model"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmDzKcIWdKzq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592644877765,"user_tz":-330,"elapsed":3395,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}},"outputId":"9ada5aea-7e16-413c-a83e-8575c26b805c"},"source":["# Wasserstein loss calculation\n","def wasserstein_loss(y_true, y_pred):\n","  return K.mean(y_true * y_pred)\n","\n","# Build and compile the critic\n","critic = build_critic()\n","critic.compile(loss=wasserstein_loss,\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","# Build the generator\n","generator = build_generator()\n","\n","# The generator takes noise as input and generated imgs\n","z = Input(shape=(latent_dim,))\n","img = generator(z)\n","  \n","# For the combined model we will only train the generator\n","critic.trainable = False\n","\n","# The critic takes generated images as input and determines validity\n","valid = critic(img)\n","\n","# The combined model  (stacked generator and critic)\n","combined = Model(z, valid)\n","combined.compile(loss=wasserstein_loss,\n","            optimizer=optimizer,\n","            metrics=['accuracy'])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_47 (Conv2D)           (None, 18, 18, 32)        320       \n","_________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)   (None, 18, 18, 32)        0         \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 18, 18, 32)        0         \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 9, 9, 64)          18496     \n","_________________________________________________________________\n","zero_padding2d_7 (ZeroPaddin (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","batch_normalization_40 (Batc (None, 10, 10, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)   (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 5, 5, 128)         73856     \n","_________________________________________________________________\n","batch_normalization_41 (Batc (None, 5, 5, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)   (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","conv2d_50 (Conv2D)           (None, 5, 5, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 5, 5, 256)         1024      \n","_________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 6400)              0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 1)                 6401      \n","=================================================================\n","Total params: 396,033\n","Trainable params: 395,137\n","Non-trainable params: 896\n","_________________________________________________________________\n","Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_25 (Dense)             (None, 20736)             2094336   \n","_________________________________________________________________\n","reshape_8 (Reshape)          (None, 9, 9, 256)         0         \n","_________________________________________________________________\n","up_sampling2d_11 (UpSampling (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 18, 18, 512)       2097664   \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 18, 18, 512)       2048      \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 18, 18, 512)       0         \n","_________________________________________________________________\n","up_sampling2d_12 (UpSampling (None, 36, 36, 512)       0         \n","_________________________________________________________________\n","conv2d_52 (Conv2D)           (None, 36, 36, 512)       4194816   \n","_________________________________________________________________\n","batch_normalization_44 (Batc (None, 36, 36, 512)       2048      \n","_________________________________________________________________\n","activation_20 (Activation)   (None, 36, 36, 512)       0         \n","_________________________________________________________________\n","conv2d_53 (Conv2D)           (None, 36, 36, 1024)      8389632   \n","_________________________________________________________________\n","batch_normalization_45 (Batc (None, 36, 36, 1024)      4096      \n","_________________________________________________________________\n","activation_21 (Activation)   (None, 36, 36, 1024)      0         \n","_________________________________________________________________\n","conv2d_54 (Conv2D)           (None, 36, 36, 1)         16385     \n","_________________________________________________________________\n","activation_22 (Activation)   (None, 36, 36, 1)         0         \n","=================================================================\n","Total params: 16,801,025\n","Trainable params: 16,796,929\n","Non-trainable params: 4,096\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JaP3aIfndWGl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592644884990,"user_tz":-330,"elapsed":2308,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}}},"source":["def train(epochs, batch_size=128, sample_interval=50):\n","  read=pd.read_csv(\"/content/drive/My Drive/CSV_28/33ksh.csv\")\n","  read1 = read.iloc[:,:].values\n","  arr=np.array\n","  arr = read1.reshape(725,36,36)\n","  # Load the dataset\n","  X_train = arr\n","\n","  # Rescale -1 to 1\n","  X_train = X_train / 127.5 - 1.\n","  X_train = np.expand_dims(X_train, axis=3)\n","\n","  # Adversarial ground truths\n","  valid = -np.ones((batch_size, 1))\n","  fake = np.ones((batch_size, 1))\n","\n","  for epoch in range(epochs):\n","    for _ in range(n_critic):\n","      # Select a random batch of images\n","      idx = np.random.randint(0, X_train.shape[0], batch_size)\n","      imgs = X_train[idx]\n","      # Sample noise as generator input\n","      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","\n","      # Generate a batch of new images\n","      gen_imgs = generator.predict(noise)\n","\n","      # Train the critic\n","      d_loss_real = critic.train_on_batch(imgs, valid)\n","      d_loss_fake = critic.train_on_batch(gen_imgs, fake)\n","      d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n","\n","      # Clip critic weights\n","      for l in critic.layers:\n","        weights = l.get_weights()\n","        weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n","        l.set_weights(weights)\n","\n","    g_loss = combined.train_on_batch(noise, valid)\n","      # Plot the progress\n","      #print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n","      # If at save interval => save generated image samples\n","    accuracy = 0\n","    if epoch % sample_interval == 0:\n","      print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n","      accuracy += 100*(1 - d_loss[1])\n","      sample_images(epoch)\n","  print(\"Accuracy: \" , accuracy/25)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBra3MdxdaK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592635952793,"user_tz":-330,"elapsed":1234,"user":{"displayName":"Riya Intwala","photoUrl":"","userId":"03077562278217522406"}}},"source":["def sample_images(epoch):\n","  r, c = 5, 5\n","  noise = np.random.normal(0, 1, (r * c, latent_dim))\n","  gen_imgs = generator.predict(noise)\n","\n","  # Rescale images 0 - 1\n","  gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","  fig, axs = plt.subplots(r, c)\n","  cnt = 0\n","  for i in range(r):\n","    for j in range(c):\n","      axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","      axs[i,j].axis('off')\n","      cnt += 1\n","  fig.savefig(\"/content/drive/My Drive/WGAN/33ksh_g/33ksh_%d.png\" % epoch)\n","  print(\"Figure Saved...........!!\")\n","  plt.close()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"uh-DbD-CRRue","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"e54a5e4f-f98c-43c1-e065-256c07d18d3e"},"source":["if __name__ == '__main__':\n","    start = time.time()\n","    train(epochs=5000, batch_size=32, sample_interval=200)\n","    end = time.time()\n","    elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) / 60),int((end - start) % 60))\n","    print(elapsed_train_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [D loss: 0.999973] [G loss: 1.000075]\n","200 [D loss: 0.999995] [G loss: 1.000054]\n","Figure Saved...........!!\n","400 [D loss: 1.000002] [G loss: 1.000086]\n","Figure Saved...........!!\n","600 [D loss: 1.000027] [G loss: 1.000116]\n","Figure Saved...........!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"utP0aPfCYEs9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}